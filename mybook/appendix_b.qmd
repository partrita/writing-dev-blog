# appendix B AI uses and abuses

To close out this book, let’s explore some uses and abuses of generative AI in the context of writing engineering blog posts. Some quick background first. Generative AI tools currently create unique responses by generating new text based on patterns learned from their training data. Some also use retrieval-augmented generation (RAG) to fetch external information and incorporate it into their responses. To offer the most clear and relevant responses, they generate text that’s statistically plausible in the given context.

NOTE We’re not going to write a primer on generative AI or large language models here. If you want that foundational knowledge, we encourage you to explore the vast and rapidly growing collection of available resources.

Applying such an immense knowledge base to your writing facilitates many tasks, from rooting out confusing sentences to predicting what questions and objections the “hive mind” might have when reading your article. But given generative AI tools’ current focus on generating plausible text based on existing data, they are unlikely to create an engineering blog post that meets the criteria outlined in chapter 3. At the time of writing, a human engineer with real development experiences, emotions, and creativity is still way more likely to excel at

¡ Intriguing discerning (and snarky) technical readers with a fresh, eye-opening topic   
Keeping them engaged with an authentic, captivating narrative

¡ Providing a distinctive educational core with deep knowledge not available elsewhere

And that leads naturally to the technology’s uses and abuses. The best uses tap the technology’s strengths to help you communicate your ideas more effectively. And the greatest abuse is using it to add any content that isn’t directly traceable to the unique elements of you: your experiences, your ideas, your voice.

Harnessed effectively, generative AI can give you superpowers. It can help you

¡ Accelerate —Rapidly prioritize related articles you might want to read, transcribe recordings you want to tap, and eliminate the tedium of formatting a long list of citations.   
¡ Boost—Perform more accurate grammar checking, get unstuck on those awk -ward sentences you can’t quite fix, discover the missing word that’s on the tip of your tongue, and create decent images despite having the artistic prowess of a three-year-old.   
¡ Crowdsource —Get instant access to what the hive mind thinks (for example, to better understand what “most people” believe about your topic and where they might expect more detail in your article).   
¡ Criticize —When you’re not (yet) ready to show your draft to fellow humans, get fast feedback on how your ideas are coming across and where you might be fall-ing short of your stated goals.   
¡ Convert—Reformat your words according to known patterns when creating meta descriptions, slide decks, and conference proposal abstracts with strict character limits.

If you’re asking generative AI to optimize your own ideas and/or writing in some way, critically reviewing the result, and then making it your own, perfect! $1 0 0 \%$ use, not abuse. If you’re blindly copy/pasting any suggested revisions or (even worse) net new generated text into your work, it’s likely abuse. All the ideas should originate from your brain and all the words should, at minimum, be filtered through it.

Let’s walk through how you might get started with some of the best uses of generative AI and conclude by looking at terrific abuses. We used ChatGPT with GPT-4o here (unless otherwise indicated), but the prompts and strategies should apply across all options.

# B.1 Clarifying sentences

Generative AI is great at pointing out suboptimal sentences. And with appropriate guidance, it can also help you improve them.

# B.1.1 Tightening long clunky sentences

To explore the range of what’s possible, we took a few different approaches to tightening up long clunky sentences: iterating on prompts within a single generative AI tool, using the same prompts across different tools, and also comparing two prompts across various tools.

# Iterating on a single tool

To quickly triage the writing in the fake Zig blog post, we prompted generative AI as follows:

P Prompt: Can you identify the longest sentences? [copy of blog post]

![](images/4a249adc07706480f5f74809f2b300009cb86870f15636b0521bf51e485c8ac2.jpg)

Response: “Zig is not Rust, and it happily lets you dereference null pointers (although its type system tries to prevent obvious cases of that), and use previously freed memory, so we had a dubious pleasure of long debugging sessions—just us, gdb, and the ninth cup of coffee—but it was comforting to see all the existing tools just work.”

“It does come with HTTP support in its standard library, and that’s great, but we also wanted to add a thin custom encryption layer, forced down our throats with all the SOC2 requirements, and that we just needed to implement by linking to a Rust implementation.”

Next, we tried to improve those two long sentences with the following prompt:

P Prompt: Please simplify each of the following sentences. Trim the fat. Do not change the meaning. It is ok to split them into multiple sentences if needed.

![](images/0958a6333641c516e7f0c29ca9c1a815c07813312b9ad346a127eb9bed5a07ec.jpg)

Response: “Zig is not Rust. It allows dereferencing null pointers and using freed memory. This led to extended debugging sessions with gdb and substantial coffee consumption, but it was reassuring to see all the existing tools function correctly.”

“Zig’s standard library includes HTTP support, which is advantageous. However, a custom encryption layer was required due to SOC2 requirements, necessitating implementation by linking to a Rust library.”

Cleaner, but soulless. These revised sentences don’t follow the style of PretendPiotr’s blog post. We tried again with another prompt.

P Prompt: Please try to keep the same personality and style used in the original draft.

![](images/f9bbf7de788641cb476bed7b921fd91cd3d8af1519d50c341dadbbccc5514332.jpg)

Response: “Zig, unlike Rust, doesn’t shy away from letting you dereference null pointers or use previously freed memory, leading to those oh-so-fun debugging marathons. But hey, it’s a relief when all your trusty tools just keep chugging along.”

“Sure, Zig’s got your back with its built-in HTTP support. But guess what? We wanted more. So, we threw in a slick custom encryption layer to keep up with all those SOC2 requirements. And yeah, it meant cozying up with a Rust implementation.”

Some personality shows here, but it seems fake and forced. And the sentences are too colloquial and too wordy. We tried again with another prompt:

![](images/338b83ca7d93676d9badcf5bcf63b8abeda8aeb826902ae125f0873ebcc86b52.jpg)

Prompt: Please simplify each of the following sentences. Trim the fat. Do not eliminate the personality or change the style. Do not change the meaning. It is ok to split them into multiple sentences if needed.

![](images/038665c007f95aa6e6af185892ffdb5e3e91f82f64f2975e4ebd4177bfcf68d7.jpg)

Response: “Zig isn’t Rust, and it happily lets you dereference null pointers and use freed memory. This led to long debugging sessions—just us, gdb, and the ninth cup of coffee—but it was comforting to see all the existing tools just work.”

“Zig’s standard library includes HTTP support, which is great. But we needed a thin custom encryption layer due to SOC2 requirements, so we had to implement it by linking to a Rust library.”

Okay, that’s an improvement. The sentences are simpler and sound relatively human. But certain nuances are lost in each sentence, just as they were when we stripped sentences down to the core actor and action in chapter 5. In both cases, you’ll want to consider if the nuances are important enough to justify the added words, then reintroduce them as you see fit. And always ensure that the final sentence truly reflects your natural voice.

If you’re not getting the results you want, even by refining the prompts, try a different generative AI tool. From our experiences, one tool is not consistently better or worse at revising, so experiment until you get something you like! That leads to our next section.

# TRYING DIFFERENT GENERATIVE AI TOOLS

To simplify an extremely wordy sentence we discovered in the wild, we tried the following prompt across a few different generative AI tools:

![](images/bf15df8d9f86e33e4adb58e245dd451ddb47c819104aa17e3813b08b357fa9a3.jpg)

Prompt: Please simplify the following text. Trim the fat. Do not eliminate the personality or change the style. It is ok to split a single sentence into multiple sentences if needed.

To overcome the scaling challenges we were facing, such as the lack of a centralized system interface for keeping and managing the growing number of business rules, as well as a previously loosely coupled infrastructure of third-party services whose many failures were impacting our sales process, around two years ago we decided to create a single platform to manage all aspects of our process for selling directly to consumers.

We got the following responses. Note the wide variety of approaches taken by different tools:

¡ Claude 3.5 Sonnet: “We faced scaling challenges: no central system for managing growing business rules and unreliable third-party services disrupting sales. Two years ago, we decided to build a single platform to handle our entire direct-to-consumer sales process.”   
¡ Gemini 1.0 Pro: “We were struggling to manage our sales. We had too many separate systems for our business rules, and third-party services kept failing, messing up our sales process. To fix this, we built a single platform two years ago to handle everything for direct sales.”   
¡ ChatGPT using GPT-4o: “To overcome our scaling challenges—like the lack of a centralized system for managing our growing number of business rules and the failures in our loosely coupled third-party services impacting sales—we created a single platform for all aspects of our direct-to-consumer sales process about two years ago.”   
¡ Copilot using GPT-4: “Around two years ago, we tackled scaling challenges. These included the lack of a centralized system interface to manage our growing business

rules and a loosely coupled infrastructure of third-party services that frequently impacted our sales process due to their numerous failures. Our solution? We created a single platform to handle all aspects of selling directly to consumers.”

The Gemini response seems best. It’s short, and it flows from one thought to another. The Copilot one also sounds natural, like it came from a human. The ChatGPT one is a bit long for a single sentence, but still clearer than the original. These three are all acceptable options. However, the Claude response is too choppy and doesn’t convey the connection between the ideas.

# Trying different tools and comparing different prompts

Next, we took a similar approach with one of the more complex sentences from the fake Zig blog post. Since PretendPiotr’s writing style has a strong personality, we wanted to compare the results with and without the “Do not eliminate the personality or change the style” statement in the prompt.

P Prompt A: Please simplify the following text. Trim the fat. Do not eliminate the personality or change the style. It is ok to split a single sentence into multiple sentences if needed.

One of the mind-blowing things about Zig is that cross compilation (ergo compiling the code to target CPU architecture and operating system different than the setup the compiler runs on) is also a core feature of the language.

P Prompt B: Please simplify the following text. Trim the fat. It is ok to split a single sentence into multiple sentences if needed.

One of the mind-blowing things about Zig is that cross compilation (ergo compiling the code to target CPU architecture and operating system different than the setup the compiler runs on) is also a core feature of the language.

Here are the results:

Table B.1 Comparing two prompts across tools   

<table><tr><td>Generative AI tool</td><td>Response to prompt A</td><td>Response to prompt B</td></tr><tr><td>Claude 3.5 Sonnet</td><td>One of Zig’s mind-blowing features is cross compilation. This means you can compile code for a different CPU and OS than what your compiler runs on. It’s built right into the language.</td><td>A remarkable feature of Zig is its built-in cross-compilation. This allows code to be compiled for different CPU architectures and operating systems than the one running the compiler.</td></tr><tr><td>Gemini 1.0 Pro</td><td>Zig rocks! Not only is it a great language, but compiling code for different systems (cross-compilation) is built right in. No need for extra tools or headaches.</td><td>Zig makes creating software for different systems incredibly easy. You can write code on one machine and compile it to run on entirely different hardware, all within the same language.</td></tr><tr><td>ChatGPT using GPT-4o</td><td>One of the mind-blowing things about Zig is that cross compilation—compiling code for a different CPU architecture and operating system than the compiler's setup—is a core feature of the language.</td><td>One impressive feature of Zig is its core support for cross-Compilation, allowing code to be compiled for different CPU architectures and operating systems from the one the compiler runs on.</td></tr><tr><td>Copilot using GPT-4</td><td>Zig's mind-blowing feature is cross-compiler. This means you can compile code to target a different CPU architecture and operating system than the one your compiler runs on.</td><td>Zig, like Rust, has native support for cross-compiler. Its integrated toolchain simplifies compiling for different architectures or operating systems. When you cross-compile from one platform to another (e.g., Windows to Linux), Zig automatically sets up the necessary import paths, making it a core feature of the language.</td></tr></table>

All tools provide distinctly different results for prompt A versus prompt B. Some of the prompt A responses capture the spirit of PretendPiotr better than others though. The Gemini response added its own words (e.g., “Zig rocks”), which seem artificial and out of place. The three-sentence Claude response is choppy. The ChatGPT response is no more readable than the original, and it leaves the reading hanging after “One of the mind-blowing things about Zig is that cross compilation.”

The Copilot response is clean and clear, and it still retains PretendPiotr’s original exuberance with “mind blowing.” Shifting from “One of the mind-blowing things about Zig is” to “Zig’s mind-blowing feature is cross-compilation” does change the emphasis and meaning a bit, though. It also skips the part about cross compilation being a core feature of the Zig language.

NOTE Interestingly, the Copilot response for prompt B added its own ideas (e.g., about automatically setting up import paths). They’re not wrong— they’re just not PretendPiotr’s thoughts. This is definitely something to watch for and a reminder of why it’s crucial to carefully review suggestions before incorporating them.

# B.1.2 Finding the right word

If you want to find a broad range of alternatives for a particular word, a thesaurus can help. But a thesaurus can’t help you when

You’re looking for a single word to replace a longer phrase.   
¡ You can’t think of a word that’s on the tip of your tongue.   
You want to focus on suggestions that make sense in your specific context.

Generative AI can help in all these cases though. Here are a few illustrative scenarios.

# Replace a weak phrase with a more precise word

Generative AI is quite helpful for sharpening a phrase in context.

![](images/9b82a29d296ec4544a15b08fe8c5ffab60a50573e789d8541a69fc7967494f1e.jpg)

Prompt: Suggest a simpler way to say “really desired” in the context of this sentence: “Such a limited trust environment is really desired for an embedded language because it vastly reduces the risk of somebody running malicious code from within your project.”

![](images/579f8534451bcdf64170bfa40ce660d6824fcaa7ac32f5bef60ed9a100c300af.jpg)

Response: “Such a limited trust environment is ideal for an embedded language…”

“Ideal” is cleaner than “really desired.”

![](images/c1c768e2b6ac5a66dcb4d9c1dd42c2ba0d0b4a6dc29bb382c4685dbbcc09a946.jpg)

Prompt: Suggest a better word than “extremely important” in the context of the following sentence: “In a distributed environment, drivers are an extremely important part of the ecosystem.”

![](images/45599aa17eafe60d0942919ee46d086a5f8ed7ff060eb30674f897a49e0d899f.jpg)

Response: “In a distributed environment, drivers are a crucial part of the ecosystem.”

“Crucial” is more emphatic than “extremely important.”

![](images/73f3b930abe56e4948769f310629e31d17c70a39fb2a0283b43ac9b342801d10.jpg)

Prompt: Suggest a simpler way to say “that happened to go through” in this context: “Instead of examining raw bytes that happened to go through our network interfaces…”

![](images/a4987558bfb15c2fe4dd0037905e8c989e0f1731eea341882a2c7b5572825d5c.jpg)

Response: “Instead of examining raw bytes that passed through our network interfaces…”

“Passed through” is easier to read than “that happened to go through.”

# Get unstuck when you can’t think of a word

Generative AI can also be a lifesaver when you have a brain freeze and just can’t come up with the right word, for whatever reason.

![](images/d004081bc450540a9a75fea6deb040af357b40872f1681d6204dbbf69b1799e5.jpg)

Prompt: What’s the right word here? “Goodput is an interesting ___ of good + throughput”?

![](images/e2086b268c200fbe10920a2f7bd2985c02d35ad8eb46e7aa22dae0f52fdd90ea.jpg)

Response: “Goodput is an interesting portmanteau of good $^ +$ throughput.”

Yep, “portmanteau” is the word we were looking for.

![](images/0dcc7f7b4132d4a7561392758a5446fcb524635e2aa3e74a44328b994d2d04e4.jpg)

Prompt: Suggest replacements for the missing word: “Filtering comes with a performance burden and is usually a ____ of data model design flaws.”

![](images/f8d864e0930e1c45cadf016127dc1fd7080a2f644f8d355817afa66a79120f18.jpg)

Response: 1. “Result” 2. “Symptom” 3. “Consequence” 4. “Manifestation” 5. “Reflection”

Ah, “symptom” is what we meant.

# B.2 Checking grammar

Generative AI’s grammar checking results were generally helpful. The tools pointed out a handful of mistakes, as well as some that were deliberate style choices. Here’s a sample:

![](images/02ce75b204eb80bd08577a8d22473027eb15e20f29475051e12df9b9198d6bc8.jpg)

Prompt: Please point out all of the grammatical problems in this blog post. Explain how to fix each one -- and why it’s a problem.

![](images/f1c32bb318e5bd0fe003a1cf6824a46cedbe3fb58263df6fda86b9a70a32c914.jpg)

Response: **First Paragraph, Last Sentence**

**Current:** There’s just one problem though, and it stems from the fact we sometimes need to move data from our legacy Postgres clusters: migrating all data back to FakeDB is S-L-O-W.

**Suggested:** There’s just one problem, though, and it stems from the fact that we sometimes need to move data from our legacy Postgres clusters: migrating all data back to FakeDB is S-L-O-W.

**Explanation:** Add a comma after “problem” for clarity, and add “that” after ”fact” for grammatical correctness.

**Migration Costs Section, Fifth Sentence**

**Current:** As a result, instead of just blindly moving data from one machine to another, we need to carefully transform it from one format to another, and the existing tools are far from ideal in that matter.

**Suggested:** As a result, instead of just blindly moving data from one machine to another, we need to carefully transform it from one format to another. The existing tools are far from ideal in that matter.

**Explanation:** Split into two sentences for clarity.

**Proposed Solution Section, First Sentence**

**Current:** It took us the aforementioned two days to establish that the existing migration machinery is far from ideal.

**Suggested:** It took us the aforementioned two days to establish that the existing migration machinery was far from ideal.

**Explanation:** Maintain tense consistency by changing “is” to “was.”

The previous problems were all valid, and should be fixed. However, the following “mistakes” reported were intentional stylistic choices, and do not warrant a correction:

![](images/c4074dcb005b8424dc56da39802a2ff4952c62bc9d3b2474aa028323a6cc3dc2.jpg)

**Developer Experience Section, Last Sentence**

**Current:** In other words, we did not enjoy it. At all.

**Suggested:** In other words, we did not enjoy it at all.

**Explanation:** Combining the two sentences into one flows better and maintains the emphasis.

**Proposed Solution Section, Second Sentence**

**Current:** Thus, it took us approximately two seconds to reach the obvious conclusion: let’s write a tool that actually works and is fun to work with!   
**Suggested:** Thus, it took us approximately two seconds to reach the obvious conclusion: let’s write a tool that actually works and is fun to use!   
**Explanation:** “Fun to use” is more concise and clearer than “fun to work with.”

We noticed that the generative AI tool didn’t report the incorrect “it’s” we had planted in the blog post (“Zig is interoperable with C alright, but it’s patience has limits.”). That raised our suspicions. Was it only reporting a subset of the problems it detected?

Curious, we prompted it with “Are there any more grammatical errors?” The tool then reported many more problems! Trying to learn from this experience, we then asked, “What prompt should I use to have you go sentence by sentence like this?” The answer—and the golden prompt for complete grammar checking—is “Please review the following text sentence by sentence for grammatical errors, suggest corrections, and explain the reasons for each correction: [insert text].”

This generates an analysis of each and every sentence, with either a correction or confirmation that it’s fine as is. Some might consider this overkill, while others might find that it puts their mind at ease. If you want an exhaustive grammatical review, that’s how to get it.

# B.3 Getting fast feedback on your rough draft

Back in chapter 4, we talked about feeding your rough draft to a generative AI tool to get fast feedback on glaring problems, like logical gaps and places where readers might expect more technical details. For fun, we decided to run one of real Piotr’s first published blog posts (“Enhancements to ScyllaDB’s Filtering Implementation,” available at https://mng.bz/M1yQ) through the same level of generative AI feedback. We asked various tools to point out problems with the blog, any logical gaps, and similar—the same prompts we used in chapter 4. Most suggestions, across tools, focused on alleged inconsistencies in the examples, the need for more details on materialized views and secondary indexes, and the limited discussion of tradeoffs.

Here are Piotr’s conclusions from that feedback:

I found most of the “detected” inconsistencies useless and untrue, but that’s entirely expected. Every model pointed out that the article didn’t get into more detail for materialized views and secondary indexes, but that’s mostly because readers were encouraged to read other blog posts and documentation if they were interested in a more detailed description. The models we used didn’t follow those links, hence they didn’t “acknowledge” the details.

e was one surprisingly brilliant

remark by Claude though: “The post mentions that filtering is performed after all potentially matching rows are fetched, but it doesn’t explicitly explain why this approach is used or if there are plans to optimize this in future versions.”

Great point! The article takes this implementation detail for granted, without explaining why all rows are fetched. Pointing out possible optimization is spot on too. My team actually discussed implementing a “replica predicate push” to optimize filtering (by trying to discard some rows early on database replicas, without fetching them to the primary). Motivated by this comment, I could have added this side note to the blog post:

“Fetching all rows to the primary node for filtering is an implementation detail, and this process can be optimized. Some predicates can be pushed to replicas, which can then reject non-matching rows early—without sending them over the network. Filtering would remain a potentially heavy operation regardless of this optimization. But, it could improve the performance enough to be faster than secondary indexes and materialized views in more use cases.”

I also encourage all authors to try Gemini. Its cluelessness with respect to blog post reviewing is really amusing, every single time. It will lighten your mood for the rest of the day!

![](images/74c4846319240bd3d9f1f2e3883445a68660a15e1dc4b71b4bfe0d903e4b1e84.jpg)

Do you notice any logical gaps in this blog post? Enhancements to ScyllaDB's Filtering Implementation

By Piotr Sarna...

Show drafts

![](images/f1064147dec71eb0be4fc0db2b0dced2231368e3f675eee00b175be5bf5a7133.jpg)

![](images/af8c8c1a7c42a1304abfb50be1681c118be04bef931a1dc50072ed8c60f2fe0a.jpg)

![](images/00e8d6a20db4d9cc4fdb37051481479fd2e7164407a74c3d2d7b2bf0b15fcb4d.jpg)

I wasn't able to find relevant information about logical gaps in the blog post on browsing the given webpage, but here is what I found from the web: there is no search result on logical gaps in the blog ALLOW FILTERING ScyllaDB.

Let me know if you have other questions!

![](images/3229341a20a7064df50452a5f6518b1ddbe5f92604b918037d9ec7bba0055b96.jpg)

![](images/42f3cb68482431b153844f0e81c000869a6758281184756cd94c1c815e1a87a7.jpg)

![](images/099d87ddc38b077de9a941d095740451c9635a7be7fb7e136e063daf7eebaedd.jpg)

![](images/90c978eac7e61906bc3b259d97d5511b85a5f5a80488c574ec830ae8073bc03e.jpg)

![](images/de44a60e8f5ff6a4371975917487c88bb70910e0198e40f25c7080447064f0a1.jpg)  
Figure B.1 Gemini’s rather clueless response to our review request. Note that the text of the entire blog post was provided in our prompt.

# B.4 Visualizing

The images we used in the patterns chapters were all generated by DALL·E 3. We had some rather specific ideas of what we wanted our images to convey, so stock images were not appropriate. Rather than hire a graphic designer, we thought it would be fun to try to create custom artwork as a generative AI learning experience.

We’re not huge fans of subscriptions and Piotr likes to use command-line tools whenever possible. That’s why we used the prepaid OpenAI API, which provides more insight into how the DALL·E 3 flow works, rather than the flashy web UI.

Sending a request to generate an image via a terminal is quite straightforward. Say you’re writing a chapter called “Lessons Learned,” and you want to decorate it with a vintage image of an 18th-century classroom during a physics lesson, inkwells and all. The image should be black-and-white and printer friendly (to avoid the editors becoming moderately angry with you at a later stage of the book publishing process). The request can look like the one in the following listing.

# Listing B.1 The request we sent

```json
curl https://api.openai.com/v1/images/generations \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $SUPERSECRET_OPENAI_TOKEN" \
-d '{ 
    "model": "dall-e-3",
    "prompt": "man in a classroom teaching physics, 18th century theme,
                    clip-art style, print friendly",
    "n": 1,
    "size": "1024x1024"
} 
```

Ideally, you would just receive a response in JSON format, containing a 'url' field pointing to the generated image. However, using the API directly revealed that DALL·E 3 has at least two stages:

1 Revising the user prompt with AI   
2 Generating the image

Figure B.2 shows the original response we received from this prompt.

![](images/76aed311a32ec43a2602d21d8848ca7d83f106848c5367304aaf75b097a3da5d.jpg)  
Figure B.2 The original image generated from our prompt requesting “man in a classroom teaching physics, 18th-century theme, clip-art style, print friendly.”

That is not exactly what we imagined. Plus, we can’t verify if what’s on the blackboards are even real words (since neither of us is a fluent Arabic speaker).

Turns out, the main culprit for this confusing response was the first stage: revising the prompt. Fortunately, the "revised_prompt" field is also returned in the response, so we could see how ChatGPT decided to revise it. Let’s just say it’s very liberal at ignoring what a user is really requesting. Here is the revised prompt.

# Listing B.2 The revised prompt

"revised_prompt": "Create a clip-art style, black and white, printerfriendly illustration of a classroom scene set in the 18th century. The setting is simple with traditional Arabic architectural elements such as arches and geometric patterns. The central figure is a female Middle-Eastern educator, dressed in 18th-century attire, perhaps with a long dress and a headscarf. She stands in front of a modest wooden desk with scrolls and quills, addressing a group of attentive students. The students, both boys and girls, are seated on low benches or cushions on the floor, taking notes on parchment. The overall composition should be clear and uncluttered, with an emphasis on the educational and cultural setting of the period."

As you can see, the style and color theme is spot on. But to ensure that the image content matches your intent, we suggest the following tricks that proved to work:

Explicitly ask to “not revise the prompt.”   
¡ Insist on particular details (e.g., clothes) quoting that it’s “extremely important for historical accuracy.”   
When asking to generate images of human beings, be weirdly specific about listing all possible historical settings, social status, ancestry, details like facial hair or lack thereof, and other things you would never mention in a normal conversation.   
Carefully check all faces and count all fingers. When in doubt, regenerate.

Another amusing thing is that models really struggle with a lack of something. Piotr once tried to generate an image of “goose footprints in a forest, BUT WITHOUT ANY GEESE PLEASE” after multiple prompts (for a children’s story, not for this book). Once you mention something in a prompt, even if it’s negated, it’s likely to appear. If you don’t want a goose in there, either carefully avoid mentioning it at all in the prompt, or be ready to refresh your Photoshop skills.

# B.5 Writing

We could tell you why you shouldn’t use generative AI to generate an engineering blog post. But we think it would be more compelling and entertaining to just show you.

We started with the following prompt, based on the stated goals for the fake Zig blog post:

![](images/3355e2ded001cad36c829aa8191fce273483692560f97550d4c71cdc3ebbace2.jpg)

Prompt: “You are an experienced software engineer who knows C, $^ { \mathsf { C } + + }$ , and Rust. Write a blog sharing your experience using Zig for a new tool you just developed to

help users migrate data to a new database. Please use a tone that is authentic, personable, and occasionally humorous.”

Here’s how it went. Please note: we did not change a single word!

# B.5.1 First attempt

![](images/e3b41f9852aa3002b32e9851d0beea89b832494b7f84c7cc260ec1e7e6645020.jpg)

## Confessions of a Data-Migrating Maverick: My Zig-Fueled Escape From $^ { \complement + + }$ Hell

Alright, fellow code slingers, buckle up for a tale of migration, redemption, and a sprinkle of Zig-flavored magic. You see, my friends, I used to be a ${ \mathsf { C } } { + } { + }$ cowboy, wrangling pointers like tumbleweeds and wrestling with templates more ferocious than a bison in a china shop. Don’t get me wrong, ${ \mathsf { C } } { + } { + }$ ’s got its grit, but for a data migration tool? It felt like trying to shoehorn a giraffe into a clown car. Enter Zig, the Rust-kissed lovechild of C and Go, promising blazing speed and memory safety that wouldn’t leave me drowning in segfaults. So, naturally, I took a leap of faith, saddled up this shiny new compiler, and rode off into the data-migrating sunset.

Let me tell you, Zig was like a breath of fresh air in a smog-choked $^ { \complement + + }$ cave. Gone were the cryptic templates and memory management migraines. Zig’s static typing held my hand like a friendly sherpa, guiding me through the treacherous landscape of data conversion. And its conciseness? Oh, it was poetry in motion. My code went from looking like a Jackson Pollock painting to a David Hockney masterpiece—clean lines, bold colors, and a damn good migration tool taking shape.

Now, don’t get me wrong, Zig ain’t all sunshine and rainbows. There were definitely bumps on the dusty trail. The ecosystem ain’t as lush as ${ \tt C } + + \tt ^ { \prime } { S }$ jungle, and some libraries felt like tumbleweeds themselves, rolling by and offering little shade. But the Zig community? Those folks are real gems. Friendlier than a puppy in a sweater, they answered my newbie questions with the patience of saints and the enthusiasm of rocket scientists. Together, we hacked our way through the rough patches, and soon, my little Zig-powered data migrant was humming like a well-oiled machine.

And the results? Well, let’s just say our users stopped using the term “migration nightmare” and started throwing around words like “breeze” and “miracle.” Turns out, using the right tool for the job can make all the difference. I went from wrangling $^ { \complement + + }$ beasts to riding the Zig breeze, and my data? It migrated smoother than a greased watermelon down a hill.

So, to all you code wranglers out there, facing down your own data migration dragons, I say this: Take a chance on Zig. It might just be the magic spell you need to turn your migration woes into coding euphoria. And hey, if you get stuck, remember, the Zig community’s got your back. Just be sure to pack your sense of humor—you’ll need it for the occasional pointer joke.

Now, if you’ll excuse me, I have a date with some freshly migrated data and a steaming cup of Zig-infused coffee. Cheers to new beginnings, fellow adventurers!

$^ { * * } \mathsf { P . S . ^ { * * } }$ To the ${ \mathsf { C } } { + } { + }$ diehards out there, hey, don’t hate the player, hate the game. $^ { \complement + + }$ will always have a special place in my dusty cowboy boots. But for data migration adventures? Zig’s the new sheriff in town, and this town ain’t big enough for the both of us.

# B.5.2 Second attempt

Once we stopped laughing/crying, we attempted to refine it a bit with the following clarification: “Less casual. And the author is a guy in Warsaw, not some American cowboy.”

Here’s the result:

![](images/83cbcd8038f249d6c9ec7ec4fa302daaca1994d23ddb6fc4896c7770afd0471b.jpg)

## From $^ { \complement + + }$ Mazurkas to Zig Polkas: A Data Migration Odyssey (Warsaw edition)

The whispers, like a Chopin nocturne, drifted through the bustling cafes of Warsaw, weaving tales of a new language. “Zig,” they murmured, “a Rust-kissed siren, promising speed without segfaults, conciseness beyond templates.” Curiosity piqued, I, a seasoned $^ { \complement + + }$ hussar, donned my compiler czapka and ventured into the uncharted territory.

Zig wasn’t just different; it was a Copernicus-level revolution. Static typing, once a barbed-wire fence, became a Żubrówka-fueled guide, steering me through the data conversion maze with surprising grace. Gone were the cryptic incantations of templates, replaced by a stark beauty as clear as a Tatry mountain lake. My ${ \mathsf { C } } { + } { + }$ code, once a Kaszubian folk song, transformed into a Mazurka masterpiece—clean lines, vibrant colors, and a data migration tool pirouetting from the keyboard.

Of course, no mazurka is without its Mazurian tumbleweeds. Zig’s ecosystem, while blossoming, lacked the sprawling forests of $^ { \complement + + }$ . Libraries occasionally felt like tumbleweeds themselves, offering little shade in the face of technical challenges. But then I stumbled upon the oasis: the Zig community. These digital szlachta, welcoming and patient, answered my every question with the enthusiasm of rocket scientists and the wisdom of seasoned górale. Together, we traversed the rocky terrain, hacking our way through opaque APIs and cryptic error messages like Krakau dragonslayers.

The culmination? A data migration tool worthy of a Polonaise ballad. Users who once lamented “koszmar!” now sang “przejrzystość!,” their datasets traversing the digital plains with the smooth glide of a Wisła gondola. Zig, it turned out, was the magic spell my codebase needed, transforming a migration odyssey into a coding Krakowiak.

To my fellow code hussars still riding the ${ \mathsf { C } } { + } { + }$ steed, I offer this: Zig might just be the pierogi your dusty compiler craves. Its efficiency is unmatched, its safety a soothing balm, and its conciseness a symphony for the coding soul. And fear not the uncharted paths—the Zig community, a beacon of camaraderie, will guide you through the code canyons with laughter and wit. Just remember to pack your sense of humor—the occasional pointer pun is inevitable.

So, saddle up, my friends, and join me on this Zig-fueled Mazurka. For in the land of data migration, a new sheriff rides, and its name is Zig.

$^ { * * } \mathsf { P . S . ^ { * * } }$ To the ${ \mathsf { C } } { + } { + }$ purists out there, I raise my virtual szklanka in respect. $^ { \complement + + }$ remains a noble steed, forever etched in the annals of coding history. But for data migration adventures, Zig holds the reins, and this digital frontier ain’t big enough for both of us.

----

This should hopefully fit the bill! While keeping the overall story and tone, I replaced the cowboy references with Polish-themed ones, adapting the language and humor to better suit a Warsaw-based author.

# B.5.3 Conclusions

That did not, in fact, fit the bill. There are words that flow—oh so amusingly—one after another, with perfect grammar. But it all rings hollow. Even though random Polish cultural references are injected throughout the text, it’s clearly not from any human being (and especially not from one with a Polish sense of humor, whatever that might entail). There’s also an untranslatable cringe feeling Polish people are going to experience when reading this article. Randomly translated words may make sense after

directly translating them back to English, but they all look ridiculously out of place.

Even Claude can tell that it’s not written by a human:

![](images/c3a2e39eeebfb763fbc4136b095711bda6c63f6dd21873ae376e293b65cf3e13.jpg)

This text appears to be AI-generated rather than written by a human. Here are the key indicators:

1. Unusually dense and consistent metaphors: The text maintains an extremely high density of Polish and Eastern European cultural references, dance metaphors, and programming analogies throughout. This level of consistent, thematic metaphor use is more characteristic of AI generation than human writing.   
2. Overly flowery language: The prose is consistently ornate and poetic in a way that feels artificial. Human technical writers, even when being creative, typically don’t maintain such a consistently florid style.   
3. Lack of specific technical details: While the post mentions Zig’s advantages, it doesn’t provide concrete examples or code snippets that a human developer would likely include based on real experience.   
4. Perfect thematic consistency: The Polish/Eastern European theme is maintained flawlessly throughout, without any drift or inconsistency that would be natural in human writing.   
5. Artificial emotional arc: The emotional journey feels manufactured rather than genuine, hitting predictable notes of curiosity, challenge, and triumph.   
6. Too-perfect structure: The post follows an idealized narrative structure that feels more like it was generated to fit a template than a natural recounting of events.   
7. Lack of genuine personal anecdotes: While framed as a personal journey, there are no specific, idiosyncratic details that would typically appear in a real developer’s account of learning a new language.   
8. Overuse of cultural references: The density of Polish references feels more like it was generated from a list than organically incorporated by someone with lived experience.

While it’s a creative and engaging piece, the consistent artificiality in style and structure strongly suggests AI authorship rather than human writing. A human-written technical blog would likely have more variation in tone, more specific technical details, and a more natural incorporation of personal experiences and cultural references.

PretendPiotr's experiences, ideas, and authentic voice came across loud and clear in the human-written blog draft. It had a few imperfections that could easily be fixed in 15 minutes or less. But even that initial draft would be much more valuable than this

AI-generated one. The reader of PretendPiotr’s initial draft would walk away with new insights on what it’s like to work with Zig, and potentially be inspired to give it a try.

With this AI-generated blog, the reader doesn’t learn a single interesting thing about using Zig. And if an engineering blog lacks a distinctive educational core, nothing else matters.

Still, there is one important educational takeaway here: you need to write your own engineering blog posts, using your own voice, based on your own experiences and ideas. By all means, feel free to use generative AI in ways that help you communicate your ideas more effectively. But if you ever think of writing engineering blog posts with generative AI instead of your own brain, just remember the dreadful example of this “Zig-fueled Mazurka.”

